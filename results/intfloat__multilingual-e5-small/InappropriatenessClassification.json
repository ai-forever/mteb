{
  "dataset_revision": "601651fdc45ef243751676e62dd7a19f491c0285",
  "evaluation_time": 13.447438716888428,
  "kg_co2_emissions": null,
  "mteb_version": "1.11.6",
  "scores": {
    "test": [
      {
        "accuracy": 0.58024,
        "ap": 0.5476512898306003,
        "f1": 0.5758618133958813,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.58024,
        "scores_per_experiment": [
          {
            "accuracy": 0.5999,
            "ap": 0.5623475279503105,
            "f1": 0.5960600458104859
          },
          {
            "accuracy": 0.6063,
            "ap": 0.5631799041363394,
            "f1": 0.6047161410584456
          },
          {
            "accuracy": 0.6141,
            "ap": 0.5738311420469193,
            "f1": 0.6091889075801037
          },
          {
            "accuracy": 0.5248,
            "ap": 0.5130003904724717,
            "f1": 0.5247292607031631
          },
          {
            "accuracy": 0.5543,
            "ap": 0.530097900419916,
            "f1": 0.5542999955429999
          },
          {
            "accuracy": 0.5694,
            "ap": 0.5384336124031008,
            "f1": 0.5601522000051073
          },
          {
            "accuracy": 0.6176,
            "ap": 0.5731581395348837,
            "f1": 0.6174704908093684
          },
          {
            "accuracy": 0.5503,
            "ap": 0.5269225164635001,
            "f1": 0.5287804936626321
          },
          {
            "accuracy": 0.5768,
            "ap": 0.5442467882632831,
            "f1": 0.5767918066893775
          },
          {
            "accuracy": 0.5889,
            "ap": 0.5512949766152779,
            "f1": 0.5864287920971301
          }
        ]
      }
    ]
  },
  "task_name": "InappropriatenessClassification"
}