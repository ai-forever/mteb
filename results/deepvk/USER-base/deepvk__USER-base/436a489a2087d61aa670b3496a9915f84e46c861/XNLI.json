{
  "dataset_revision": "09698e0180d87dc247ca447d3a1248b931ac0cdb",
  "evaluation_time": 2.5123157501220703,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.25",
  "scores": {
    "test": [
      {
        "cos_sim": {
          "accuracy": 0.7003663003663003,
          "accuracy_threshold": 0.4979301989078522,
          "ap": 0.7663937519600628,
          "f1": 0.7270408163265306,
          "f1_threshold": 0.44973891973495483,
          "precision": 0.6433408577878104,
          "recall": 0.8357771260997068
        },
        "dot": {
          "accuracy": 0.7003663003663003,
          "accuracy_threshold": 0.49793025851249695,
          "ap": 0.7663937519600628,
          "f1": 0.7270408163265306,
          "f1_threshold": 0.44973888993263245,
          "precision": 0.6433408577878104,
          "recall": 0.8357771260997068
        },
        "euclidean": {
          "accuracy": 0.7003663003663003,
          "accuracy_threshold": 1.0020675659179688,
          "ap": 0.7663937519600628,
          "f1": 0.7270408163265306,
          "f1_threshold": 1.0490577220916748,
          "precision": 0.6433408577878104,
          "recall": 0.8357771260997068
        },
        "hf_subset": "ru",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.7664864675662042,
        "manhattan": {
          "accuracy": 0.7047619047619048,
          "accuracy_threshold": 22.328296661376953,
          "ap": 0.7664864675662042,
          "f1": 0.7269205939315688,
          "f1_threshold": 23.09436798095703,
          "precision": 0.649365628604383,
          "recall": 0.8255131964809385
        },
        "max": {
          "accuracy": 0.7047619047619048,
          "ap": 0.7664864675662042,
          "f1": 0.7270408163265306
        }
      }
    ],
    "validation": [
      {
        "cos_sim": {
          "accuracy": 0.7223443223443223,
          "accuracy_threshold": 0.5199145078659058,
          "ap": 0.7834283752881649,
          "f1": 0.7271531886916502,
          "f1_threshold": 0.44938546419143677,
          "precision": 0.6591179976162098,
          "recall": 0.8108504398826979
        },
        "dot": {
          "accuracy": 0.7223443223443223,
          "accuracy_threshold": 0.5199145674705505,
          "ap": 0.7834283752881649,
          "f1": 0.7271531886916502,
          "f1_threshold": 0.4493855834007263,
          "precision": 0.6591179976162098,
          "recall": 0.8108504398826979
        },
        "euclidean": {
          "accuracy": 0.7223443223443223,
          "accuracy_threshold": 0.979883074760437,
          "ap": 0.783428375288165,
          "f1": 0.7271531886916502,
          "f1_threshold": 1.0493946075439453,
          "precision": 0.6591179976162098,
          "recall": 0.8108504398826979
        },
        "hf_subset": "ru",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.783428375288165,
        "manhattan": {
          "accuracy": 0.7208791208791209,
          "accuracy_threshold": 21.784366607666016,
          "ap": 0.7832102919490093,
          "f1": 0.7241157556270097,
          "f1_threshold": 23.392221450805664,
          "precision": 0.6449026345933563,
          "recall": 0.8255131964809385
        },
        "max": {
          "accuracy": 0.7223443223443223,
          "ap": 0.783428375288165,
          "f1": 0.7271531886916502
        }
      }
    ]
  },
  "task_name": "XNLI"
}